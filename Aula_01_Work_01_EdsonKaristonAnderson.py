# -*- coding: utf-8 -*-
"""Aula_01_Work_02.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/18SxQO0eFj8Huf_0xJXO3nLMZnFUL0-hR

# **Aula - 01 / Work - 2**

## **Classificando genomas de COVID-19 com técnicas de dados desbalanceados**

### **Alunos:**

 - Anderson Salata de Abreu
 - Edson Alves
 - Kariston Stevan Luiz

A classificação de sequências virais tem sido uma preocupação de infectologistas e epidemiologistas há décadas, dado o desafio de detectar vírus altamente divergentes ou desconhecidos, por exemplo, pandemia de COVID-19 causada por novos vírus SARS-CoV-2. Em 28 de maio de 2020, o SARS-CoV-2 afetou mais de 188 países / regiões, com mais de 5,7 milhões de infectados e 356.000 mortes. Outros fatores agravantes dessa doença são que a maioria dos pacientes pode não apresentar sintomas, transformando-os em portadores silenciosos. Além disso, o SARS-CoV-2 tem semelhanças com outros tipos de coronavírus, dificultando a distinção deles sem testes. Acreditamos que os algoritmos de aprendizado de máquina podem ser uma ferramenta potencialmente poderosa para prever sequências virais, auxiliando na luta contra a pandemia de COVID-19.

## **Dataset**

**Identificação de seqüências SARS-CoV-2 de outros vírus**

Aqui, realizamos um teste experimental, mas agora classificando a SARS-CoV-2 de outros vírus (por exemplo, HIV, gripe, hepatite, ebolavírus, SARS, etc). Dessa forma, baixamos todas as sequências de vírus disponíveis (29.135) do banco de dados do NCBI Viral Genome (genoma completo). sequências, mesma consulta Completude do nucleotídeo = "complete" AND host = "homo sapiens"). Como pré-processamento, removemos sequências menores que 2.000pb e maiores que 50.000pb e que se cruzam com nosso conjunto inicial, para eliminar qualquer viés no tamanho da sequência, uma vez que o SARS-CoV-2 tem um comprimento médio de 29.838pb. Assim, obtemos um conjunto de dados final com **22.442** e **2.373** sequências de outros vírus e SARS-CoV-2, respectivamente.

## **Imbalanced data sets (dados desbalanceados)**

A classe desbalanceada ocorre quando temos um dataset que possui muitos exemplos de uma classe e poucos exemplos da outra classe (**conforme apresentado no dataset de COVID**). Nessa situação se você tem um modelo de classificação, por exemplo, o resultado pode ser enviesado, ou seja ele tende a classificar os novos dados como sendo da classe que possui mais exemplos.

https://github.com/scikit-learn-contrib/imbalanced-learn

https://machinelearningmastery.com/smote-oversampling-for-imbalanced-classification/

## **Trabalho**

Use o dataset **other_viruses_covid.csv** para construir um modelo de classificação de sequências de COVID-19.

Use Holdout (ou Cross-Validation, Stratified, leave-one-out, bootstrap) para avaliar qual dos algoritmos escolhidos (pelo menos dois) tem melhores resultados nos dados, alguns exemplos:

    SVM Linear
    SVM RBF
    K vizinhos
    Decision Tree

Decida que padronização dos dados usará para cada algoritmo (ou nenhuma). Justifique.

Teste pelo menos duas técnicas para dados desbalanceados (ver aquivo **Imbalanced data sets**).

Faça o grid search dos hiperparametros apropriados para cada algoritmo escolhido (ver arquivo **grid search**).

Reporte pelos menos três métricas de performance de cada algoritmo.

Finalmente, discorra rapidamente sobre os experimentos e resultados (qual o melhor classificador, qual melhor métrica, aplicar técnicas de dados desbalanceados teve efeito nesse problema, qual a melhor parametrização do algoritmo utilizado...).

**Caso ainda tenha dúvida de como montar um modelo de classificação, procure o arquivo "Construindo um modelo de classificação" no conteúdo complementar da disciplina.**

## **Carregando dataset**
"""

# Código aqui!
import pandas as pd
data = pd.read_csv(r'D:\POS\BigDataSistemasInteligentesSENAI\20_aula1_ReconhecimentoDePadroes\atividade1\other_viruses_covid.csv')
data = data.drop(columns=['nameseq'])
data

"""## **Segue montagem ...**"""

X = data.iloc[:, :-1]
y = data.iloc[:, -1]

from sklearn.model_selection import train_test_split

train, test, train_labels, test_labels = train_test_split(X,
                                                          y,
                                                          test_size=0.3,
                                                          random_state=12,
                                                          stratify=y)

train

test

from sklearn.preprocessing import MinMaxScaler

sc = MinMaxScaler(feature_range=(0, 1))

train = sc.fit_transform(train)

test = sc.transform(test)

train

test

from sklearn import tree

classifier = tree.DecisionTreeClassifier()

classifier.fit(train, train_labels)

preds = classifier.predict(test)

preds

import warnings
warnings.filterwarnings("ignore")
from sklearn.metrics import roc_auc_score
from sklearn.metrics import accuracy_score
from sklearn.metrics import cohen_kappa_score
from sklearn.metrics import confusion_matrix
from sklearn.metrics import hamming_loss
from sklearn.metrics import f1_score
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score
from sklearn.metrics import matthews_corrcoef
from imblearn.metrics import geometric_mean_score

accuracy = accuracy_score(test_labels, preds)
matriz = (pd.crosstab(test_labels, preds, rownames=["REAL"], colnames=["PREDITO"], margins=True))
hamming = hamming_loss(test_labels, preds)
# matriz_confu = confusion_matrix(test_labels, preds)
f1 = f1_score(test_labels, preds, average=None)
mcc = matthews_corrcoef(test_labels, preds) 

print("Accuracy %s" % (accuracy))
print("\n")
print("%s" % (matriz))
print("\n")
print("Hamming %s" % (hamming))
print("\n")
print("F1 Score %s" % (f1))
print("\n")
print("MCC %s" % (mcc))
print("\n")

from sklearn.naive_bayes import GaussianNB

gnb = GaussianNB()

gnb.fit(train, train_labels)

preds2 = gnb.predict(test)
preds2

accuracy = accuracy_score(test_labels, preds2)
matriz = (pd.crosstab(test_labels, preds2, rownames=["REAL"], colnames=["PREDITO"], margins=True))
hamming = hamming_loss(test_labels, preds2)
f1 = f1_score(test_labels, preds2, average=None)
mcc = matthews_corrcoef(test_labels, preds2) 

print("Accuracy %s" % (accuracy))
print("\n")
print("%s" % (matriz))
print("\n")
print("Hamming %s" % (hamming))
print("\n")
print("F1 Score %s" % (f1))
print("\n")
print("MCC %s" % (mcc))
print("\n")
